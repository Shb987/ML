{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10877130-1557-4bc7-8d05-a4ce294ad004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa3a0443-835f-45ea-8fc4-b3c09ca7ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiral_train_healthy_path = r\"C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\training\\healthy\"\n",
    "spiral_train_park_path = r\"C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\training\\parkinson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4073bb6a-3393-49a7-ad3c-2c6779170f12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spiral_train_healthy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Training Healthy Samples: \u001b[39m\u001b[38;5;124m'\u001b[39m ,\u001b[38;5;28mlen\u001b[39m(\u001b[43mspiral_train_healthy\u001b[49m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Training Parkinson Samples: \u001b[39m\u001b[38;5;124m'\u001b[39m ,\u001b[38;5;28mlen\u001b[39m(spiral_train_park))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Testing Healthy Samples: \u001b[39m\u001b[38;5;124m'\u001b[39m ,\u001b[38;5;28mlen\u001b[39m(spiral_test_healthy))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spiral_train_healthy' is not defined"
     ]
    }
   ],
   "source": [
    "print('Total Training Healthy Samples: ' ,len(spiral_train_healthy))\n",
    "print('Total Training Parkinson Samples: ' ,len(spiral_train_park))\n",
    "print('Total Testing Healthy Samples: ' ,len(spiral_test_healthy))\n",
    "print('Total Testing Parkinson  Samples: ' ,len(spiral_test_park))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a526c9-018a-447f-ab85-493c416292e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spiral_train_healthy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining dataset contain \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mspiral_train_healthy\u001b[49m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(spiral_train_park)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of 2 classes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting dataset contain \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(spiral_test_healthy)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(spiral_test_park)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of 2 classes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spiral_train_healthy' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Training dataset contain {len(spiral_train_healthy)+len(spiral_train_park)} of 2 classes')\n",
    "print(f'Testing dataset contain {len(spiral_test_healthy)+len(spiral_test_park)} of 2 classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc7e03-5893-4357-bae1-267ee4db90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "for i in spiral_train_park:\n",
    "    x.append(spiral_train_park_path+ \"\\\\\" +i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e2621-25bb-4b51-8df7-a9c586cc5576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=[]\n",
    "for i in spiral_train_healthy:\n",
    "    y.append(spiral_train_healthy_path+\"\\\\\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591c34b-0aa5-44fe-a162-40602032d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure(sample_path,label):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        image=plt.imread(sample_path[i])\n",
    "        plt.imshow(image)\n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65222e0-033a-4a18-9d5f-36284ff157da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(y,'Healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3767396-04bf-4743-9012-572fe7e5fca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98045b76-bedb-4c95-93f4-5db09b1f4980",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(x,'Parkinson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9fcbb2-176a-4b8d-9893-c88b4e55c01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d759aaa-349d-49b3-94f2-1a05a6a3e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Update the extract_features function to include DWT coefficients\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        # HOG features\n",
    "        hog_features = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2))\n",
    "        \n",
    "        # LBP features\n",
    "        lbp = local_binary_pattern(img, 8, 1, method='uniform')\n",
    "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 9), density=True)\n",
    "        \n",
    "        # Gabor features\n",
    "        frequency = 0.4\n",
    "        thetas = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "        gabor_features = []\n",
    "        for theta in thetas:\n",
    "            gabor_real, gabor_imaginary = np.real(gabor_kernel(frequency, theta=theta)), np.imag(gabor_kernel(frequency, theta=theta))\n",
    "            gabor_features.append(np.mean(ndi.convolve(img, gabor_real)))\n",
    "            gabor_features.append(np.mean(ndi.convolve(img, gabor_imaginary)))\n",
    "        \n",
    "        # DWT coefficients\n",
    "        coeffs = pywt.dwt2(img, 'haar')\n",
    "        cA, (cH, cV, cD) = coeffs\n",
    "        dwt_features = np.concatenate((cA.ravel(), cH.ravel(), cV.ravel(), cD.ravel()))\n",
    "        \n",
    "        # Concatenate all features\n",
    "        all_features = np.concatenate((hog_features, lbp_hist, gabor_features, dwt_features))\n",
    "        features.append(all_features)\n",
    "    return np.array(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a517b-7afe-4821-adb7-5872a2421c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        # Resize image to (200, 200)\n",
    "        img_resized = cv2.resize(img, (200, 200))\n",
    "        \n",
    "        # # Thresholding\n",
    "        thresholded_image = cv2.threshold(img_resized, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "        \n",
    "        processed_images.append(thresholded_image)\n",
    "    return np.array(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679a3cd-1b51-4acb-9673-7b986cd43b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.filters import gabor_kernel\n",
    "from scipy import ndimage as ndi\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Function to load images and labels\n",
    "\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, category in enumerate(['healthy', 'parkinson']):\n",
    "        label_dir = os.path.join(data_dir, category)\n",
    "        for image_file in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, image_file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                # Ensure all images have the same shape\n",
    "                img = cv2.resize(img, (200, 200))  # Replace desired_width and desired_height with your desired dimensions\n",
    "                images.append(img)\n",
    "                labels.append(label)  # Assigning 0 for healthy and 1 for Parkinson's\n",
    "    return np.array(images), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c576c63-a037-4c34-8f0d-6cb0c8828c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "wave_training_healthy_images, wave_training_healthy_labels = load_data(r'C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\training')\n",
    "wave_training_parkinson_images, wave_training_parkinson_labels = load_data(r'C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\training')\n",
    "wave_test_healthy_images, wave_test_healthy_labels = load_data(r'C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\testing')\n",
    "wave_test_parkinson_images, wave_test_parkinson_labels = load_data(r'C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\testing')\n",
    "\n",
    "# Combine training and testing data\n",
    "X_train = np.concatenate((wave_training_healthy_images, wave_training_parkinson_images), axis=0)\n",
    "y_train = np.concatenate((wave_training_healthy_labels, wave_training_parkinson_labels), axis=0)\n",
    "X_test = np.concatenate((wave_test_healthy_images, wave_test_parkinson_images), axis=0)\n",
    "y_test = np.concatenate((wave_test_healthy_labels, wave_test_parkinson_labels), axis=0)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3d66b-1ba5-4b6b-bb98-06da0d06f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test[1].shape)\n",
    "# Preprocess images (if needed)\n",
    "X_train_preprocessed = preprocess_images(X_train)\n",
    "X_test_preprocessed = preprocess_images(X_test)\n",
    "\n",
    "print(\"Shape of X_train_preprocessed:\", X_train_preprocessed.shape)\n",
    "print(\"Shape of X_train_preprocessed:\", X_test_preprocessed.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0944b-6cb6-495d-9969-fc1709e7a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "X_train_features = extract_features(X_train_preprocessed)\n",
    "X_test_features = extract_features(X_test_preprocessed)\n",
    "\n",
    "print(\"Shape of training features:\", X_train_features.shape)\n",
    "print(\"Shape of testing features:\", X_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c41d3d-1e22-4643-8f39-462115c42ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to display preprocessed images\n",
    "def display_images(images, labels, num_images=5):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i], cmap='gray')\n",
    "        axes[i].set_title('Label: {}'.format(labels[i]))\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display preprocessed images\n",
    "display_images(X_test_preprocessed, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c134cf87-cf81-4478-b3fc-207b69ac5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "\n",
    "# Train the classifier\n",
    "svm_classifier.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "train_predictions = svm_classifier.predict(X_train_features)\n",
    "\n",
    "# Calculate accuracy on the training set\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0830d-7829-4177-98d0-563c4e6f14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "test_predictions = svm_classifier.predict(X_test_features)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69057b93-38d9-416e-bab0-65d0d56da805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "        processed_images = []\n",
    "        # Resize image to (200, 200)\n",
    "        img_resized = cv2.resize(images, (200, 200))\n",
    "        \n",
    "        # # Thresholdinga\n",
    "        thresholded_image = cv2.threshold(img_resized, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "        \n",
    "        processed_images.append(thresholded_image)\n",
    "        return np.array(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0222d-2261-4bb3-baad-6d9b8bf5f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path = r'C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\testing\\parkinson\\V03PE07.png'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the image (assuming you have a preprocess_images function)\n",
    "image_preprocessed = preprocess_images(image)\n",
    "\n",
    "# Extract features from the preprocessed image (assuming you have an extract_features function)\n",
    "image_features = extract_features(image_preprocessed)\n",
    "\n",
    "# Reshape the features array to match the expected input shape of the model\n",
    "image_features = image_features.reshape(1, -1)\n",
    "\n",
    "# Use the trained model to predict the label of the image\n",
    "prediction = svm_classifier.predict(image_features)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"Predicted Label: {}\".format(\"Healthy\" if prediction == 0 else \"Parkinson's\"))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1abb614-f68b-464b-9fc8-30297dcecf00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd1fbe-c357-48d7-b7d9-3cdd75244a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path = r'C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\testing\\parkinson\\V06PE01.png'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the image (assuming you have a preprocess_images function)\n",
    "image_preprocessed = preprocess_images(image)\n",
    "\n",
    "# Extract features from the preprocessed image (assuming you have an extract_features function)\n",
    "image_features = extract_features(image_preprocessed)\n",
    "\n",
    "# Reshape the features array to match the expected input shape of the model\n",
    "image_features = image_features.reshape(1, -1)\n",
    "\n",
    "# Use the trained model to predict the label of the image\n",
    "prediction = svm_classifier.predict(image_features)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"Predicted Label: {}\".format(\"Healthy\" if prediction == 0 else \"Parkinson's\"))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f9f09-ede1-4ec9-8bd7-d091e0cc7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path = r'C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\testing\\parkinson\\V14PE03.png'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the image (assuming you have a preprocess_images function)\n",
    "image_preprocessed = preprocess_images(image)\n",
    "\n",
    "# Extract features from the preprocessed image (assuming you have an extract_features function)\n",
    "image_features = extract_features(image_preprocessed)\n",
    "\n",
    "# Reshape the features array to match the expected input shape of the model\n",
    "image_features = image_features.reshape(1, -1)\n",
    "\n",
    "# Use the trained model to predict the label of the image\n",
    "prediction = svm_classifier.predict(image_features)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"Predicted Label: {}\".format(\"Healthy\" if prediction == 0 else \"Parkinson's\"))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e88f6a-5a2d-4b5e-9dc0-e7e5bc69d277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e9a87-4342-4fe8-b90a-eb24441ebf67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877aa8fb-1a5d-4a62-b05d-e87ef8678ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51294e12-9367-4852-b96c-5873861cb23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf_classifier.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "rf_train_predictions = rf_classifier.predict(X_train_features)\n",
    "\n",
    "# Calculate training accuracy\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_train_predictions)\n",
    "print(\"Random Forest Training Accuracy:\", rf_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d5b4c-4b10-49f7-8ba7-d8268dd6a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predict on the test set\n",
    "rf_predictions = rf_classifier.predict(X_test_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b71c5-b7ed-43b4-89f1-6c1d155c5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', random_state=42)\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "lr_classifier.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "lr_train_predictions = lr_classifier.predict(X_train_features)\n",
    "\n",
    "# Calculate training accuracy\n",
    "lr_train_accuracy = accuracy_score(y_train, lr_train_predictions)\n",
    "print(\"Logistic Regression Training Accuracy:\", lr_train_accuracy)\n",
    "\n",
    "# Predict on the test set\n",
    "lr_test_predictions = rf_classifier.predict(X_test_features)\n",
    "\n",
    "# Calculate testing accuracy\n",
    "lr_test_accuracy = accuracy_score(y_test, lr_test_predictions)\n",
    "print(\"Logistic Regression Testing Accuracy:\", lr_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e36cc-0527-405b-be50-a256381d31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path =  r'C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\testing\\parkinson\\V06PE01.png'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the image (assuming you have a preprocess_images function)\n",
    "image_preprocessed = preprocess_images(image)\n",
    "\n",
    "# Extract features from the preprocessed image (assuming you have an extract_features function)\n",
    "image_features = extract_features(image_preprocessed)\n",
    "\n",
    "# Reshape the features array to match the expected input shape of the model\n",
    "image_features = image_features.reshape(1, -1)\n",
    "\n",
    "# Use the trained model to predict the label of the image\n",
    "prediction = rf_classifier.predict(image_features)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"Predicted Label: {}\".format(\"Healthy\" if prediction == 0 else \"Parkinson's\"))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca58920-1601-4e9e-a7b3-d02cd17d1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path =  r'C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\testing\\parkinson\\V14PE03.png'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the image (assuming you have a preprocess_images function)\n",
    "image_preprocessed = preprocess_images(image)\n",
    "\n",
    "# Extract features from the preprocessed image (assuming you have an extract_features function)\n",
    "image_features = extract_features(image_preprocessed)\n",
    "\n",
    "# Reshape the features array to match the expected input shape of the model\n",
    "image_features = image_features.reshape(1, -1)\n",
    "\n",
    "# Use the trained model to predict the label of the image\n",
    "prediction = rf_classifier.predict(image_features)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"Predicted Label: {}\".format(\"Healthy\" if prediction == 0 else \"Parkinson's\"))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79b95a-95bc-4eac-a7bd-2931f7111542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path =  r'C:\\Users\\shiha\\OneDrive\\Desktop\\playground\\parkinson_musiliar_college\\Datasets\\spiral\\testing\\parkinson\\V03PE07.png'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the image (assuming you have a preprocess_images function)\n",
    "image_preprocessed = preprocess_images(image)\n",
    "\n",
    "# Extract features from the preprocessed image (assuming you have an extract_features function)\n",
    "image_features = extract_features(image_preprocessed)\n",
    "\n",
    "# Reshape the features array to match the expected input shape of the model\n",
    "image_features = image_features.reshape(1, -1)\n",
    "\n",
    "# Use the trained model to predict the label of the image\n",
    "prediction = rf_classifier.predict(image_features)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"Predicted Label: {}\".format(\"Healthy\" if prediction == 0 else \"Parkinson's\"))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4b66a-024c-4781-a534-c69ef12935c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Step 1: Bagging and Boosting\n",
    "# Random Forest (Bagging)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_features, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test_features)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# AdaBoost (Boosting)\n",
    "adaboost_classifier = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "adaboost_classifier.fit(X_train_features, y_train)\n",
    "adaboost_predictions = adaboost_classifier.predict(X_test_features)\n",
    "adaboost_accuracy = accuracy_score(y_test, adaboost_predictions)\n",
    "print(\"AdaBoost Accuracy:\", adaboost_accuracy)\n",
    "\n",
    "# Gradient Boosting (Boosting)\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_classifier.fit(X_train_features, y_train)\n",
    "gb_predictions = gb_classifier.predict(X_test_features)\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
    "print(\"Gradient Boosting Accuracy:\", gb_accuracy)\n",
    "\n",
    "# Step 2: Stacking\n",
    "# Train base models\n",
    "base_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "base_adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "base_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "base_models = [base_rf, base_adaboost, base_gb]\n",
    "stacking_train_predictions = []\n",
    "\n",
    "for model in base_models:\n",
    "    model.fit(X_train_features, y_train)\n",
    "    train_predictions = model.predict(X_train_features)\n",
    "    stacking_train_predictions.append(train_predictions)\n",
    "\n",
    "# Stack base model predictions to create meta-features\n",
    "stacking_train_predictions = np.array(stacking_train_predictions).T\n",
    "\n",
    "# Train meta-model (Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(stacking_train_predictions, y_train)\n",
    "\n",
    "# Make predictions on test data for base models\n",
    "stacking_test_predictions = []\n",
    "\n",
    "for model in base_models:\n",
    "    test_predictions = model.predict(X_test_features)\n",
    "    stacking_test_predictions.append(test_predictions)\n",
    "\n",
    "# Stack base model predictions to create meta-features for test data\n",
    "stacking_test_predictions = np.array(stacking_test_predictions).T\n",
    "\n",
    "# Predict using meta-model\n",
    "stacking_predictions = meta_model.predict(stacking_test_predictions)\n",
    "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
    "print(\"Stacking Accuracy:\", stacking_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00e179-62b3-4bb0-8d17-67b736c273cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966aadeb-c008-4569-83f1-0c17e47f593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_features, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test_features)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "gb_classifier.fit(X_train_features, y_train)\n",
    "gb_predictions = gb_classifier.predict(X_test_features)\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
    "print(\"Gradient Boosting Accuracy:\", gb_accuracy)\n",
    "\n",
    "# Support Vector Machine (SVM) Classifier\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_classifier.fit(X_train_features, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test_features)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "lr_classifier = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', random_state=42)\n",
    "lr_classifier.fit(X_train_features, y_train)\n",
    "lr_predictions = lr_classifier.predict(X_test_features)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42751f81-83ff-4134-a4e3-31777b078794",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = {\n",
    "    'Model': ['Random Forest', 'Gradient Boosting', 'SVM', 'Logistic Regression'],\n",
    "    'Accuracy': [rf_accuracy, gb_accuracy, svm_accuracy, lr_accuracy]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991d6b7-ef85-4f77-a5b6-cc77db9ac109",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df = pd.DataFrame(accuracy_scores,index=['a','b','c','d'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d17d18-22d8-4f38-bafe-e2b9360b6a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206d6a0-9622-40df-a3ad-d3f56d156a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predictions)\n",
    "rf_class_report = classification_report(y_test, rf_predictions)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_conf_matrix = confusion_matrix(y_test, gb_predictions)\n",
    "gb_class_report = classification_report(y_test, gb_predictions)\n",
    "\n",
    "# Support Vector Machine (SVM) Classifier\n",
    "svm_conf_matrix = confusion_matrix(y_test, svm_predictions)\n",
    "svm_class_report = classification_report(y_test, svm_predictions)\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "lr_conf_matrix = confusion_matrix(y_test, lr_predictions)\n",
    "lr_class_report = classification_report(y_test, lr_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a54984-ba70-4526-b8e5-425a37022c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print(\"Random Forest Confusion Matrix:\\n\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(rf_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", rf_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435bea2-431b-4da9-b29e-7daf57387845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8df554-bddb-4215-b4e0-63ffeb1392fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_conf_matrix = confusion_matrix(y_test, svm_predictions)\n",
    "svm_class_report = classification_report(y_test, svm_predictions)\n",
    "\n",
    "gb_conf_matrix = confusion_matrix(y_test, gb_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(gb_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Gradient Boosting Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "gb_class_report = classification_report(y_test, gb_predictions)\n",
    "print(\"\\nGradient Boosting Classification Report:\\n\", gb_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63696c4f-cfbd-498b-a9b2-33d2ccc63e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_conf_matrix = confusion_matrix(y_test, lr_predictions)\n",
    "lr_class_report = classification_report(y_test, lr_predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(lr_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGradient Boosting Classification Report:\\n\", lr_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36272677-dc58-4617-9f6c-c2c92e669fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(svm_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('SVM Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGradient Boosting Classification Report:\\n\", svm_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1939e-9672-420f-a19e-c56398c812f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('rf_classifier.pkl','wb') as file:\n",
    "    pickle.dump(rf_classifier,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
